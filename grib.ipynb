{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime, timedelta\n",
    "from io import BytesIO, StringIO\n",
    "from logging import info, warning\n",
    "from typing import Dict, Optional\n",
    "\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelConfig:\n",
    "    short_name: str\n",
    "    model_hour_interval: int\n",
    "    s3_bucket: str\n",
    "    s3_prefix_pattern: str\n",
    "    s3_grib_file_name_pattern: str\n",
    "    s3_idx_file_name_pattern: str\n",
    "    s3_complete_run_number_of_files: int\n",
    "    parameters: Dict[str, str]\n",
    "\n",
    "    def get_s3_grib_key(self, run: datetime, forecast: int) -> str:\n",
    "        return self.s3_prefix_pattern.format(\n",
    "            run=run\n",
    "        ) + self.s3_grib_file_name_pattern.format(run=run, forecast=forecast)\n",
    "\n",
    "    def get_s3_idx_key(self, run: datetime, forecast: int) -> str:\n",
    "        return self.s3_prefix_pattern.format(\n",
    "            run=run\n",
    "        ) + self.s3_idx_file_name_pattern.format(run=run, forecast=forecast)\n",
    "\n",
    "    def get_grib_file_name(self, run: datetime, forecast: int) -> str:\n",
    "        return self.s3_grib_file_name_pattern.format(run=run, forecast=forecast)\n",
    "\n",
    "    def get_idx_file_name(self, run: datetime, forecast: int) -> str:\n",
    "        return self.s3_idx_file_name_pattern.format(run=run, forecast=forecast)\n",
    "\n",
    "    def get_s3_prefix(self, run: datetime) -> str:\n",
    "        return self.s3_prefix_pattern.format(run=run)\n",
    "\n",
    "\n",
    "gfs_config = ModelConfig(\n",
    "    short_name=\"gfs\",\n",
    "    model_hour_interval=6,\n",
    "    s3_bucket=\"noaa-gfs-bdp-pds\",\n",
    "    s3_prefix_pattern=\"gfs.{run:%Y%m%d}/{run:%H}/atmos/\",\n",
    "    s3_grib_file_name_pattern=\"gfs.t{run:%H}z.pgrb2.0p25.f{forecast:03d}\",\n",
    "    s3_idx_file_name_pattern=\"gfs.t{run:%H}z.pgrb2.0p25.f{forecast:03d}.idx\",\n",
    "    s3_complete_run_number_of_files=418,\n",
    "    parameters={},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_possible_model_run(model_hour_interval: int) -> datetime:\n",
    "    \"\"\"Gets the latest possible model run time based on the current\n",
    "    utc time.\n",
    "\n",
    "    Args:\n",
    "        model_hour_interval (int): The interval between model runs in hours.\n",
    "    Returns:\n",
    "        datetime: Datetime object representing the latest possible model run\n",
    "    \"\"\"\n",
    "    now = datetime.utcnow()\n",
    "    current_hour = now.hour\n",
    "    nearest_possible_model_hour = model_hour_interval * (\n",
    "        current_hour // model_hour_interval\n",
    "    )\n",
    "\n",
    "    delta_hours = current_hour - nearest_possible_model_hour\n",
    "    if delta_hours <= 3:\n",
    "        delta_hours += 6\n",
    "\n",
    "    nearest_model_time = now - timedelta(\n",
    "        hours=delta_hours,\n",
    "        minutes=now.minute,\n",
    "        seconds=now.second,\n",
    "        microseconds=now.microsecond,\n",
    "    )\n",
    "\n",
    "    return nearest_model_time\n",
    "\n",
    "\n",
    "def get_latest_run(\n",
    "    model_config: ModelConfig, max_runs_to_try: int = 3\n",
    ") -> Optional[datetime]:\n",
    "    \"\"\"Attempts to find a complete GFS model run available on S3\n",
    "    from a specified number of previous run times.\n",
    "\n",
    "    Args:\n",
    "        model_config (ModelConfig): The model configuration.\n",
    "        max_runs_to_try (int, optional): The number of runs to check for\n",
    "                                         completeness. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        Optional[datetime]: Datetime object representing the latest complete run.\n",
    "    \"\"\"\n",
    "    expected_number_of_files = model_config.s3_complete_run_number_of_files\n",
    "    model_hour_interval = model_config.model_hour_interval\n",
    "    bucket = model_config.s3_bucket\n",
    "\n",
    "    latest_possible_run = get_latest_possible_model_run(\n",
    "        model_hour_interval=model_hour_interval\n",
    "    )\n",
    "\n",
    "    runs_to_try = [\n",
    "        latest_possible_run - timedelta(hours=i * model_hour_interval)\n",
    "        for i in range(max_runs_to_try)\n",
    "    ]\n",
    "\n",
    "    s3_client = boto3.client(\"s3\", config=Config(signature_version=UNSIGNED))\n",
    "\n",
    "    for run in runs_to_try:\n",
    "        prefix = model_config.get_s3_grib_key(run=run, forecast=0).rstrip(\"0\")\n",
    "        info(\n",
    "            f\"Checking {run:%Y%m%d %H}Z model run for completeness. (S3 prefix - s3://{bucket}/{prefix})\"\n",
    "        )\n",
    "        result = s3_client.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    "        if contents := result.get(\"Contents\"):\n",
    "            num_files_found = len(contents)\n",
    "            info(\n",
    "                f\"Found {num_files_found} files available for {run:%Y%m%d %H}Z model run.\"\n",
    "            )\n",
    "            if num_files_found == expected_number_of_files:\n",
    "                latest_run = run\n",
    "                info(f\"Found complete run: {latest_run:%Y%m%d %HZ}\")\n",
    "                return latest_run\n",
    "\n",
    "        else:\n",
    "            info(\n",
    "                f\"Found no files available for {run:%Y%m%d %H}Z model run. (S3 Prefix - {prefix})\"\n",
    "            )\n",
    "\n",
    "    warning(f\"No complete runs found in previous {max_runs_to_try} runs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_idx_file(\n",
    "    model_config: ModelConfig, run: datetime, forecast: int\n",
    ") -> Optional[str]:\n",
    "    \"\"\"Gets the idx file for the given run and forecast provided it does not already exist in the current directory.\n",
    "\n",
    "    run (datetime): The run time of the model.\n",
    "    forecast (int): The forecast hour.\n",
    "\n",
    "    returns (Optional[str]): The name of the idx file.\n",
    "    \"\"\"\n",
    "    prefix = model_config.get_s3_prefix(run=run)\n",
    "    bucket = model_config.s3_bucket\n",
    "    idx_file = model_config.get_s3_idx_key(run=run, forecast=forecast)\n",
    "    s3_client = boto3.client(\"s3\", config=Config(signature_version=UNSIGNED))\n",
    "    local_file_name = model_config.get_idx_file_name(run=run, forecast=forecast)\n",
    "\n",
    "    if os.path.exists(local_file_name):\n",
    "        info(f\"File {idx_file} already exists locally.\")\n",
    "        return local_file_name\n",
    "    try:\n",
    "        info(f\"Downloading {idx_file} from S3...\")\n",
    "        s3_client.download_file(bucket, idx_file, local_file_name)\n",
    "    except s3_client.exceptions.NoSuchKey as e:\n",
    "        warning(f\"File {idx_file} not found on S3. {e}\")\n",
    "    else:\n",
    "        info(f\"Successfully downloaded {idx_file}.\")\n",
    "\n",
    "    return local_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_grib_index(index: StringIO) -> Dict[str, Dict[str, Dict[str, Optional[int]]]]:\n",
    "    \"\"\"Parses a grib index file into a usable dictionary.\n",
    "    Args:\n",
    "        index (str): The contents of the grib index file.\n",
    "    Returns:\n",
    "        Dict[str, Dict[str, Dict[str, Optional[int]]]]: A dictionary containing parameter, level,\n",
    "            and start/stop byte addresses.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    prev_start = None\n",
    "    index.seek(0)\n",
    "    for line in index.read().split(\"\\n\")[::-1]:\n",
    "        if len(line) != 0:\n",
    "            _, start, _, parameter, level, _ = line.rstrip(\":\").split(\":\")\n",
    "            stop = prev_start - 1 if prev_start is not None else None\n",
    "            byte_locations = {\"start\": int(start), \"stop\": stop}\n",
    "            if parameter in result.keys():\n",
    "                result[parameter][level] = byte_locations\n",
    "            else:\n",
    "                result[parameter] = {level: byte_locations}\n",
    "\n",
    "            prev_start = int(start)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grib_message_from_s3(\n",
    "    bucket: str, key: str, start_byte: int, stop_byte: int\n",
    ") -> bytes:\n",
    "    \"\"\"Downloads a single grib message from s3 using the s3 url and start/stop bytes\"\"\"\n",
    "    s3_client = boto3.client(\"s3\", config=Config(signature_version=UNSIGNED))\n",
    "    range_header = {\"Range\": f\"bytes={start_byte}-{stop_byte}\"}\n",
    "    response = s3_client.get_object(Bucket=bucket, Key=key, **range_header)\n",
    "    return response[\"Body\"].read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if latest_run := get_latest_run(model_config=gfs_config):\n",
    "    idx_test_file = get_test_idx_file(\n",
    "        model_config=gfs_config, run=latest_run, forecast=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grib_key = gfs_config.get_s3_grib_key(run=latest_run, forecast=0)\n",
    "print(grib_key)\n",
    "if idx_test_file := get_test_idx_file(\n",
    "    model_config=gfs_config, run=latest_run, forecast=0\n",
    "):\n",
    "    with open(idx_test_file, \"r\") as f:\n",
    "        grib_index = parse_grib_index(index=f)\n",
    "\n",
    "bucket = gfs_config.s3_bucket\n",
    "parameter = grib_index.get(\"TMP\")\n",
    "level = parameter.get(\"2 m above ground\")\n",
    "start_byte = level.get(\"start\")\n",
    "stop_byte = level.get(\"stop\")\n",
    "grib_message = get_grib_message_from_s3(\n",
    "    bucket=bucket, key=grib_key, start_byte=start_byte, stop_byte=stop_byte\n",
    ")\n",
    "assert grib_message[:4] == b\"GRIB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import NamedTemporaryFile\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "lat = 40.0\n",
    "lon = 105.0\n",
    "if grib_message is not None:\n",
    "    with NamedTemporaryFile(mode=\"wb\") as file:\n",
    "        file.write(grib_message)\n",
    "        ds = xr.open_dataset(file.name, engine=\"cfgrib\")\n",
    "        print(ds.coords)\n",
    "        print(ds.t2m.interp(latitude=lat, longitude=lon, method=\"linear\").values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb4a0ac80907d7f44e1a5e88d3d3381b33e3dbedd3a24d113e876f30a0c46bee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
